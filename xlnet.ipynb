{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_KH5YcXyoqfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "wbir2kxXee3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, XLNetTokenizer, XLNetConfig, XLNetForSequenceClassification\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Diplomamunka/Suicide_Detection.csv')\n",
        "\n",
        "# Convert 'class' to numerical format\n",
        "df['class'] = df['class'].map({'suicide': 1, 'non-suicide': 0})\n",
        "\n",
        "# Split dataset into texts and labels\n",
        "texts, labels = df['text'].tolist(), df['class'].tolist()\n",
        "\n",
        "# Split data into training, validation, and test sets\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(texts,\n",
        "                                                                      labels,\n",
        "                                                                      test_size=0.15,\n",
        "                                                                      random_state=42)\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts,\n",
        "                                                                    train_labels,\n",
        "                                                                    test_size=0.1764,\n",
        "                                                                    random_state=42)  # 0.1764 ~ 0.15 / (1 - 0.15)\n",
        "\n",
        "# XLNet setup\n",
        "config = XLNetConfig.from_pretrained(\"xlnet-base-cased\", dropout=0.3)\n",
        "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", config=config)\n",
        "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "# Function to encode texts and convert to torch tensors\n",
        "def encode_texts(texts):\n",
        "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512)  # Limit max length\n",
        "    seq = torch.tensor(encodings['input_ids'])\n",
        "    mask = torch.tensor(encodings['attention_mask'])\n",
        "    return seq, mask\n",
        "\n",
        "train_seq, train_mask = encode_texts(train_texts)\n",
        "val_seq, val_mask = encode_texts(val_texts)\n",
        "test_seq, test_mask = encode_texts(test_texts)\n",
        "\n",
        "train_y = torch.tensor(train_labels)\n",
        "val_y = torch.tensor(val_labels)\n",
        "test_y = torch.tensor(test_labels)\n",
        "\n",
        "# Dataloader preparation\n",
        "batch_size = 8\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=0.0008)\n",
        "\n",
        "# Early Stopping parameters\n",
        "patience = 5\n",
        "best_val_loss = float('inf')\n",
        "no_improvement = 0\n",
        "best_model = None\n",
        "\n",
        "training_losses = []\n",
        "validation_losses = []\n",
        "validation_metrics = []\n",
        "\n",
        "epochs = 20\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(train_dataloader)*epochs)\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_dataloader):\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        outputs = model(sent_id, attention_mask=mask, labels=labels)\n",
        "        loss = outputs[0]\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    training_losses.append(avg_loss)\n",
        "    print(f'Epoch {epoch+1}, Training Loss: {avg_loss}')\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    total_val_loss = 0\n",
        "    for batch in val_dataloader:\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(sent_id, attention_mask=mask, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "    validation_losses.append(avg_val_loss)\n",
        "    print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss}')\n",
        "\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        no_improvement = 0\n",
        "        best_model = model.state_dict()\n",
        "        torch.save(best_model, '/content/drive/MyDrive/Colab Notebooks/Diplomamunka/Models/my_best_model_xlnet.pt')  # Save it\n",
        "    else:\n",
        "        no_improvement += 1\n",
        "        if no_improvement == patience:\n",
        "            print(f'Stopping early after {epoch+1} epochs due to no improvement in validation loss.')\n",
        "            break\n",
        "\n",
        "# Load the best model\n",
        "model.load_state_dict(best_model)\n",
        "\n",
        "# Evaluation function to calculate metrics\n",
        "def evaluate_model(dataloader):\n",
        "    model.eval()\n",
        "\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(sent_id, attention_mask=mask)\n",
        "            logits = outputs[0]\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "            predictions.extend(np.argmax(logits, axis=1))\n",
        "            true_labels.extend(label_ids)\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='binary')\n",
        "    mcc = matthews_corrcoef(true_labels, predictions)\n",
        "\n",
        "    return accuracy, precision, recall, f1, mcc\n",
        "\n",
        "# Compute metrics for train and test sets\n",
        "train_metrics = evaluate_model(train_dataloader)\n",
        "val_metrics = evaluate_model(val_dataloader)\n",
        "test_metrics = evaluate_model(test_dataloader)\n",
        "\n",
        "print(\"Train Metrics: Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}, MCC: {:.4f}\".format(*train_metrics))\n",
        "print(\"Validation Metrics: Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}, MCC: {:.4f}\".format(*val_metrics))\n",
        "print(\"Test Metrics: Accuracy: {:.4f}, Precision: {:.4f}, Recall: {:.4f}, F1: {:.4f}, MCC: {:.4f}\".format(*test_metrics))\n",
        "\n",
        "# ------------------------------\n",
        "def get_predictions(dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for batch in tqdm(dataloader):\n",
        "        batch = [t.to(device) for t in batch]\n",
        "        sent_id, mask, labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(sent_id, attention_mask=mask)\n",
        "            logits = outputs[0]\n",
        "            logits = logits.detach().cpu().numpy()\n",
        "            label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "            predictions.extend(logits)\n",
        "            true_labels.extend(label_ids)\n",
        "\n",
        "    return predictions, true_labels\n",
        "\n",
        "# Get predictions for train, validation, and test sets\n",
        "train_predictions, train_true_labels = get_predictions(train_dataloader)\n",
        "val_predictions, val_true_labels = get_predictions(val_dataloader)\n",
        "test_predictions, test_true_labels = get_predictions(test_dataloader)\n",
        "\n",
        "# Calculate ROC-AUC scores for train, validation, and test sets\n",
        "train_roc_auc = roc_auc_score(train_true_labels, train_predictions)\n",
        "val_roc_auc = roc_auc_score(val_true_labels, val_predictions)\n",
        "test_roc_auc = roc_auc_score(test_true_labels, test_predictions)\n",
        "\n",
        "# Calculate confusion matrix for train, validation, and test sets\n",
        "train_confusion_matrix = confusion_matrix(train_true_labels, np.argmax(train_predictions, axis=1))\n",
        "val_confusion_matrix = confusion_matrix(val_true_labels, np.argmax(val_predictions, axis=1))\n",
        "test_confusion_matrix = confusion_matrix(test_true_labels, np.argmax(test_predictions, axis=1))\n",
        "\n",
        "# Save confusion matrices to CSV files\n",
        "pd.DataFrame(train_confusion_matrix).to_csv('/content/drive/MyDrive/Colab Notebooks/Diplomamunka/Results/train_confusion_matrix_xlnet.csv', index=False)\n",
        "pd.DataFrame(val_confusion_matrix).to_csv('/content/drive/MyDrive/Colab Notebooks/Diplomamunka/Results/val_confusion_matrix_xlnet.csv', index=False)\n",
        "pd.DataFrame(test_confusion_matrix).to_csv('/content/drive/MyDrive/Colab Notebooks/Diplomamunka/Results/test_confusion_matrix_xlnet.csv', index=False)\n",
        "\n",
        "# Save ROC-AUC scores to CSV file\n",
        "roc_auc_df = pd.DataFrame({'Dataset': ['Train', 'Validation', 'Test'],\n",
        "                           'ROC-AUC': [train_roc_auc, val_roc_auc, test_roc_auc]})\n",
        "roc_auc_df.to_csv('/content/drive/MyDrive/Colab Notebooks/Diplomamunka/Results/roc_auc_scores_xlnet.csv', index=False)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(training_losses, label='Training Loss')\n",
        "plt.plot(validation_losses, label='Validation Loss')\n",
        "plt.title('Training & Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tjbsRDu4ogZa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}